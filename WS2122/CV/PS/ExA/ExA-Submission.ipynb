{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eda294e",
   "metadata": {},
   "source": [
    "# Computer Vision PS (WS21/22)\n",
    "\n",
    "## Exercise sheet A (ExA)\n",
    "\n",
    "**Group members**: *please list all group members here*\n",
    "\n",
    "**Total (possible) points**: 8 (+1 bonus point)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ad6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14da9a",
   "metadata": {},
   "source": [
    "### ExA.1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f01c04",
   "metadata": {},
   "source": [
    "In this exercise, create a 2D tensor (i.e., a matrix) $\\mathbf{A}$ of size $20 \\times 20$ and fill all entries $a_{ij}, 1 \\leq i,j\\leq 20$ with values drawn from a Gaussian distribution with mean 3 and std. deviation 1.5, i.e., $\\mathcal{N}(3,1.5)$. Leverage PyTorch functionality as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bef46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE GOES HERE\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b800b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Testing code \n",
    "#\n",
    "print('Mean of tensor:      {:.3f}'.format(A.mean()))\n",
    "print('Std. dev. of tensor: {:.3f}'.format(A.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c659be",
   "metadata": {},
   "source": [
    "### ExA.2 (4 points)\n",
    "\n",
    "In this exercise, we first create a 2D `numpy.ndarray` named `inp` (size $2 \\times 8$) of type `np.float32`. We say that each row represents a 1D signal of length 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c71c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([[1,2,3,4,5,6,7,8],\n",
    "               [10,11,12,13,14,15,16,17]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15927d5",
   "metadata": {},
   "source": [
    "The goal now is to *decompose* these two 1D signals into **sliding windows** and store the results in a tensor.\n",
    "\n",
    "In particular, we want to slide a window of length $L$ over each signal, where the window is moved forward by $S>=1$ steps a time. In our exercise, $L=3$ and $S=2$. \n",
    "\n",
    "To give a concrete example, take the first 1D signal `[1,2,3,4,5,6,7,8]`. Under the given sliding window settings $L=3$ and $S=1$, the result would be `[1,2,3]`, `[3,4,5]`, `[5,6,7]`. In other words, we obtain three sliding windows.  As both 1D signals are of equal length, the overall result (for the two 1D signals) should be stored in a tensor of size `(2,3,3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fc7b0",
   "metadata": {},
   "source": [
    "**Implementation hints**:\n",
    "\n",
    "One (quite efficient way) to implement this is to use the method `sliding_window_view` from `numpy.lib.stride_tricks` (this requires `numpy` version $\\geq$ 1.20.0); see documentation [here](https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.sliding_window_view.html).\n",
    "\n",
    "Once you have correctly called `numpy.lib.stride_tricks.sliding_window_view`, the result will again be a `numpy.ndarray`, so you have to convert it into a PyTorch tensor. \n",
    "\n",
    "To take the step size $S$ into account, you can simply use the slicing syntax of PyTorch tensors. Any singleton dimension can eventually be *squeezed* using `torch.Tensor.squeeze`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2278c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def win(X, L=3, S=2):\n",
    "    \"\"\"\n",
    "    Implementation of the sliding window decomposition.\n",
    "    \n",
    "    Arguments:\n",
    "        X: numpy.ndarray\n",
    "           Input numpy.ndarray of size (N,D), i.e., N 1D signals of length D\n",
    "\n",
    "        L: int            \n",
    "           Length of the sliding window (e.g., 3)\n",
    "        \n",
    "        S: int\n",
    "           Step size to move the sliding window forward (e.g., 2)\n",
    "            \n",
    "    Returns:\n",
    "        torch.Tensor\n",
    "            Output tensor of size (N,W,width), i.e., N 1D signals, decomposed\n",
    "            into W windows of length L\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    #\n",
    "    # YOUR CODE GOES HERE\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c343bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Testing code\n",
    "#\n",
    "ret = win(inp,3,2)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d5c38",
   "metadata": {},
   "source": [
    "While you do not have to follow the **implementation hints** above, you will get a bonus point if your code runs efficiently. E.g., you can time your code via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b43a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_large = torch.rand(250,1000)\n",
    "%timeit win(inp_large, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dddd56",
   "metadata": {},
   "source": [
    "If implemented well, this should run in approx. 700-900 $\\mu$s (obviously depending on your system)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986ae373",
   "metadata": {},
   "source": [
    "### ExA.3 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd69fd4",
   "metadata": {},
   "source": [
    "Below, we initialize a tensor of size `(3,4,6,7,10)` with elements drawn from a standard Gaussian distribution, i.e., $\\mathcal{N}(0,1)$. Compute the Frobenius norm over all $7 \\times 10$ matrices in the last two dimensions. This should give a tensor of size `(3,4,6)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9364bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "R = torch.randn(3,4,6,7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1c2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE GOES HERE\n",
    "# \n",
    "# normR = ...\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Testing code\n",
    "#\n",
    "testR = torch.from_numpy(np.load('testR.npy'))\n",
    "print('Diff: {:.3f}'.format(torch.linalg.norm(testR-normR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55230295",
   "metadata": {},
   "source": [
    "### ExA.4 (1 point)\n",
    "\n",
    "Implement the following functions:\n",
    "\n",
    "- $f_0: \\mathbb{R} \\to \\mathbb{R}$, $x \\mapsto \\max\\{0,x\\}$ \n",
    "- $f_1: \\mathbb{R} \\to \\mathbb{R}$, $x \\mapsto \\frac{1}{1+e^{-x}}$ \n",
    "\n",
    "\n",
    "and plot the function graph for 100 inputs, linearly spaced in $[-5,5]$. For the latter, use `torch.linspace` to create such an input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9182a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0(inp):\n",
    "    #\n",
    "    # YOUR CODE GOES HERE\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(inp):\n",
    "    #\n",
    "    # YOUR CODE GOES HERE\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c647373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plotting\n",
    "#\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# YOUR PLOTTING CODE GOES HERE\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
